{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import Dropout, Activation, Dense, BatchNormalization\n",
    "from keras.layers import Flatten, Convolution2D, MaxPooling2D\n",
    "from keras.models import load_model\n",
    "from keras import layers, optimizer_v2\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEED 고정\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "random.seed(SEED)\n",
    "\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(tf.random.uniform([1]))\n",
    "print(tf.random.uniform([1]))\n",
    "print(tf.random.uniform([1]))\n",
    "\n",
    "print(random.random())\n",
    "print(random.random())\n",
    "print(random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real = np.load('dataset/x_real.npz')['data']\n",
    "y_real = np.load('dataset/y_real.npy')\n",
    "x_easy = np.load('dataset/x_easy.npz')['data']\n",
    "y_easy = np.load('dataset/y_easy.npy')\n",
    "x_medium = np.load('dataset/x_medium.npz')['data']\n",
    "y_medium = np.load('dataset/y_medium.npy')\n",
    "x_hard = np.load('dataset/x_hard.npz')['data']\n",
    "y_hard = np.load('dataset/y_hard.npy')\n",
    "\n",
    "print(x_real.shape, y_real.shape)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(y_real[0])\n",
    "plt.imshow(x_real[0].squeeze(), cmap='gray')\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(y_easy[0])\n",
    "plt.imshow(x_easy[0].squeeze(), cmap='gray')\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(y_medium[0])\n",
    "plt.imshow(x_medium[0].squeeze(), cmap='gray')\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(y_hard[0])\n",
    "plt.imshow(x_hard[0].squeeze(), cmap='gray')\n",
    "\n",
    "print(x_real[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.concatenate([x_easy, x_medium, x_hard], axis=0)\n",
    "label_data = np.concatenate([y_easy, y_medium, y_hard], axis=0)\n",
    "\n",
    "x_train, x_val, label_train, label_val = train_test_split(x_data, label_data, test_size=0.2)\n",
    "\n",
    "print(x_data.shape, label_data.shape)\n",
    "print(x_train.shape, label_train.shape)\n",
    "print(x_val.shape, label_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [x_data[40000]] * 9\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    # blur images with a sigma of 0 to 0.5\n",
    "    iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "    iaa.Affine(\n",
    "        # scale images to 90-110% of their size, individually per axis\n",
    "        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "        # translate by -10 to +10 percent (per axis)\n",
    "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "        # rotate by -30 to +30 degrees\n",
    "        rotate=(-30, 30),\n",
    "        # use nearest neighbour or bilinear interpolation (fast)\n",
    "        order=[0, 1],\n",
    "        # if mode is constant, use a cval between 0 and 255\n",
    "        cval=255\n",
    "    )\n",
    "], random_order=True)\n",
    "\n",
    "augs = seq.augment_images(augs)\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(2, 5, 1)\n",
    "plt.title('original')\n",
    "plt.imshow(x_data[40000].squeeze(), cmap='gray')\n",
    "for i, aug in enumerate(augs):\n",
    "    plt.subplot(2, 5, i+2)\n",
    "    plt.title('aug %02d' % int(i+1))\n",
    "    plt.imshow(aug.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Label Dictionary Lookup Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_real_dict = {}\n",
    "\n",
    "for i, y in enumerate(y_real):\n",
    "    key = y.astype(str)\n",
    "    key = ''.join(key).zfill(6)\n",
    "\n",
    "    label_real_dict[key] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, x, label, x_real, label_real_dict, batch_size=300, shuffle=True):\n",
    "        'Initialization'\n",
    "        self.x = x\n",
    "        self.label = label\n",
    "        self.x_real = x_real\n",
    "        self.label_real_dict = label_real_dict\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return int(np.floor(len(self.x) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        x1_batch = self.x[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        label_batch = self.label[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        \n",
    "        x2_batch = np.empty((self.batch_size, 90, 90, 1), dtype=np.float32)\n",
    "        y_batch = np.zeros((self.batch_size, 1), dtype=np.float32)\n",
    "        \n",
    "        # augmentation\n",
    "        if self.shuffle:\n",
    "            seq = iaa.Sequential([\n",
    "                iaa.Affine(\n",
    "                    scale={\"x\": (0.7, 1.3), \"y\": (0.7, 1.3)},\n",
    "                    translate_percent={\"x\": (-0.3, 0.3), \"y\": (-0.3, 0.3)},\n",
    "                    rotate=(-30, 30),\n",
    "                    order=[0, 1],\n",
    "                    cval=255\n",
    "                )\n",
    "            ], random_order=True)\n",
    "\n",
    "            x1_batch = seq.augment_images(x1_batch)\n",
    "        \n",
    "        #pick matched images(label 1.0) and unmatched images(label 0.0) and put together in batch\n",
    "        #matched images must be all same, [subject_id(3), gender(1), left_right(1), finger(1)], e.g) 034010\n",
    "        for i, l in enumerate(label_batch):\n",
    "            match_key = l.astype(str)\n",
    "            match_key = ''.join(match_key).zfill(6)\n",
    "\n",
    "            if random.random() > 0.5:\n",
    "                # put matched image\n",
    "                x2_batch[i] = self.x_real[self.label_real_dict[match_key]]\n",
    "                y_batch[i] = 1.\n",
    "            else:\n",
    "                # put unmatched image\n",
    "                while True:\n",
    "                    unmatch_key, unmatch_idx = random.choice(list(self.label_real_dict.items()))\n",
    "\n",
    "                    if unmatch_key != match_key:\n",
    "                        break\n",
    "\n",
    "                x2_batch[i] = self.x_real[unmatch_idx]\n",
    "                y_batch[i] = 0.\n",
    "\n",
    "        return [x1_batch.astype(np.float32) / 255., x2_batch.astype(np.float32) / 255.], y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            self.x, self.label = shuffle(self.x, self.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = DataGenerator(x_train, label_train, x_real, label_real_dict, shuffle=True)\n",
    "val_gen = DataGenerator(x_val, label_val, x_real, label_real_dict, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = layers.Input(shape=(90, 90, 1))\n",
    "x2 = layers.Input(shape=(90, 90, 1))\n",
    "\n",
    "# share weights both inputs\n",
    "inputs = layers.Input(shape=(90, 90, 1))\n",
    "\n",
    "feature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "feature = layers.MaxPooling2D(pool_size=2)(feature)\n",
    "\n",
    "feature = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(feature)\n",
    "feature = layers.MaxPooling2D(pool_size=2)(feature)\n",
    "\n",
    "feature_model = Model(inputs=inputs, outputs=feature)\n",
    "\n",
    "# 2 feature models that sharing weights\n",
    "x1_net = feature_model(x1)\n",
    "x2_net = feature_model(x2)\n",
    "\n",
    "# subtract features\n",
    "net = layers.Subtract()([x1_net, x2_net])\n",
    "\n",
    "net = layers.Conv2D(32, kernel_size=3, padding='same', activation='relu')(net)\n",
    "net = layers.MaxPooling2D(pool_size=2)(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "\n",
    "net = layers.Dense(64, activation='relu')(net)\n",
    "\n",
    "net = layers.Dense(1, activation='sigmoid')(net)\n",
    "\n",
    "model = Model(inputs=[x1, x2], outputs=net)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(learning_rate = 0.0007) ,metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_FOLDER_PATH = 'model/'\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + '0912.h5'\n",
    "\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_accuracy',\n",
    "                                verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(train_gen, epochs=30,callbacks=[cb_checkpoint], validation_data=val_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new user fingerprint input\n",
    "from keras.models import load_model\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "model_list = glob.glob('model/*.h5')\n",
    "model_name = model_list[-1]\n",
    "\n",
    "best_model = load_model(model_name)\n",
    "\n",
    "img1_name = 'test_data/'\n",
    "img2_name = 'test_data/'\n",
    "\n",
    "input_img1 = cv2.imread(img1_name ,cv2.IMREAD_GRAYSCALE)\n",
    "input_img2 = cv2.imread(img2_name, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "\n",
    "input_img11 = cv2.resize(input_img1, (90, 90)).reshape((1, 90, 90, 1)).astype(np.float32) /255\n",
    "input_img22 = cv2.resize(input_img2, (90, 90)).reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "\n",
    "input_data = []\n",
    "input_data.append(input_img11)\n",
    "input_data.append(input_img22)\n",
    "input_data = np.array(input_data)\n",
    "\n",
    "pred_rx = best_model.predict((input_data[0], input_data[1]))\n",
    "\n",
    "if pred_rx > 0.5:\n",
    "    print('score={} : matched'.format(pred_rx))\n",
    "    fig, axes = plt.subplots(1,2,figsize = (12,12))\n",
    "    axes[0].set_title(\"input1\")\n",
    "    axes[0].imshow(input_img1)\n",
    "    axes[1].set_title(\"input2\")\n",
    "    axes[1].imshow(input_img2)\n",
    "    print('WorkingTime: {}sec'.format(time.time()-start_time))\n",
    "\n",
    "else:\n",
    "    print('score={} : unmatched'.format(pred_rx))\n",
    "    fig, axes = plt.subplots(1,2,figsize = (12,12))\n",
    "    axes[0].set_title(\"input1\")\n",
    "    axes[0].imshow(input_img1)\n",
    "    axes[1].set_title(\"input2\")\n",
    "    axes[1].imshow(input_img2)\n",
    "    print('WorkingTime: {}sec'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new user fingerprint input\n",
    "from keras.models import load_model\n",
    "import cv2\n",
    "\n",
    "model = load_model('/Users/qsiik/Desktop/fingerprint_from_image/model/0629.h5')\n",
    "\n",
    "random_idx = random.randint(0, len(x_val))\n",
    "\n",
    "random_img = x_val[random_idx]\n",
    "random_label = label_val[random_idx]\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "    iaa.GaussianBlur(sigma=(0, 0.5)),\n",
    "    iaa.Affine(\n",
    "        scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)},\n",
    "        translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)},\n",
    "        rotate=(-30, 30),\n",
    "        order=[0, 1],\n",
    "        cval=255\n",
    "    )\n",
    "], random_order=True)\n",
    "\n",
    "random_img = seq.augment_image(random_img).reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "\n",
    "# matched image\n",
    "match_key = random_label.astype(str)\n",
    "match_key = ''.join(match_key).zfill(6)\n",
    "\n",
    "rx = x_real[label_real_dict[match_key]].reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "ry = y_real[label_real_dict[match_key]]\n",
    "\n",
    "pred_rx = model.predict([random_img, rx])\n",
    "\n",
    "# unmatched image\n",
    "unmatch_key, unmatch_idx = random.choice(list(label_real_dict.items()))\n",
    "\n",
    "ux = x_real[unmatch_idx].reshape((1, 90, 90, 1)).astype(np.float32) / 255.\n",
    "uy = y_real[unmatch_idx]\n",
    "\n",
    "pred_ux = model.predict([random_img, ux])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input: %s' %random_label)\n",
    "plt.imshow(random_img.squeeze(), cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('O: %.02f, %s' % (pred_rx, ry))\n",
    "plt.imshow(rx.squeeze(), cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('X: %.02f, %s' % (pred_ux, uy))\n",
    "plt.imshow(ux.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('python3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3292922a618ca9f3a4e1cf088f6eaea80205f29535491ef474467c2b8876dcf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
